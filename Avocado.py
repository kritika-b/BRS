#!/usr/bin/env python
# coding: utf-8

# # BOOK RECOMMENDATION

# # Importing the necessary Python libraries 

# In[158]:


#data manipulation and analysis
import pandas as pd
#core computing used for scientific compuuting,includes powerful n-dimensional array object, procides tool 
import numpy as np
from scipy.sparse import csr_matrix
import sklearn
from sklearn.decomposition import TruncatedSVD
#Truncated Singular Value Decomposition (truncatedSVD) used for dimentionality reduction
import warnings
warnings.filterwarnings('ignore')
#warnings package can eliminate any warnings that occurs during the procedure


# # Importing Dataset

# In[159]:


book = pd.read_csv('BX-Books.csv', sep=';', error_bad_lines=False, encoding='latin-1')
book.columns = ['ISBN', 'bookTitle', 'bookAuthor', 'yearOfPublication', 'Publisher', 'imageUrlS', 'imageUrlM', 'imageUrlL']

user = pd.read_csv('BX-Users.csv', sep=';', error_bad_lines=False, encoding='latin-1')
user.columns = ['userID', 'Location', 'Age']

rating = pd.read_csv('BX-Book-Ratings.csv', sep=';', error_bad_lines=False, encoding='latin-1')
rating.columns = ['userID', 'ISBN', 'bookRating']


# In[160]:


book.head()


# In[161]:


book.drop(['imageUrlS', 'imageUrlM', 'imageUrlL'], axis=1, inplace=True)
#displaying top5 rows of the data
book.head()


# In[162]:


book.dtypes


# # Users data Pre-processing

# In[163]:


print(user.shape)
print(list(user.columns))


# In[164]:


user.head()


# In[165]:


user.dtypes


# In[166]:


user.userID.values


# In[167]:


print(sorted(user.Age.unique()))


# In[168]:


user.loc[(user.Age > 90) | (user.Age < 5),'Age']=np.nan
user.Age=user.Age.fillna(user.Age.mean())
user.Age=user.Age.astype(np.int32)


# In[169]:


print(sorted(user.Age.unique()))


# # Ratings dataset

# In[170]:


print(rating.shape)
print(list(rating.columns))


# In[171]:


rating.head()


# # Popularity Basis Recommendation System

# In[172]:


combine_book_rating = pd.merge(rating, book, on='ISBN')
columns = ['yearOfPublication', 'Publisher', 'bookAuthor']
combine_book_rating = combine_book_rating.drop(columns, axis=1)
combine_book_rating.head()


# In[173]:


combine_book_rating = combine_book_rating.dropna(axis=0, subset= ['bookTitle'])


# In[174]:


book_ratingCount = (combine_book_rating.groupby(by = ['bookTitle'])['bookRating'].count().reset_index().rename(columns = {'bookRating' : 'totalRatingCount'})[['bookTitle', 'totalRatingCount']])
book_ratingCount.head()


# In[175]:


rating_with_totalRatingCount = combine_book_rating.merge(book_ratingCount, left_on = 'bookTitle', right_on = 'bookTitle', how ='left')
rating_with_totalRatingCount.head()


# In[176]:


pd.set_option('display.float_format', lambda x: '%.3f' % x)
print(book_ratingCount['totalRatingCount'].describe())


# In[177]:


print(book_ratingCount['totalRatingCount'].quantile(np.arange(.9, 1, .01)))


# In[178]:


popularity_threshold = 100
rating_popular_book = rating_with_totalRatingCount.query('totalRatingCount >= @popularity_threshold')
rating_popular_book.head()


# # FilterTo Users in US & CANADA only

# In[179]:


combined = rating_popular_book.merge(user, left_on ='userID', right_on= 'userID', how='left')
#here, combined data is been generated by using the principle of joins as in the Database concepts
#joining btw rating_popular_book and user by using left join
us_canada_user_rating = combined[combined['Location'].str.contains("usa|canada")]
us_canada_user_rating = us_canada_user_rating.drop('Age', axis = 1)

us_canada_user_rating.head()


# # Implemneting kNN:

# In[180]:


us_canada_user_rating = us_canada_user_rating.drop_duplicates(['userID', 'bookTitle'])
#At first creating a pivot table by using certain columns such as bookTitle,userID and bookRating
#Fill nonfill with 0
us_canada_user_rating_pivot = us_canada_user_rating.pivot_table(index = 'bookTitle', columns= 'userID', values = 'bookRating').fillna(0)
#Later converting the formed pivot table into matrix form
us_canada_user_rating_matrix = csr_matrix(us_canada_user_rating_pivot.values)


# In[181]:


from sklearn.neighbors import NearestNeighbors  # to implement knn algo

model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute')
model_knn.fit(us_canada_user_rating_matrix)
#KNN model fitting and distance measure considered is cosine


# # Test our model & make some recommendations:

# In[182]:


query_index = np.random.choice(us_canada_user_rating_pivot.shape[0])
distances, indices = model_knn.kneighbors(us_canada_user_rating_pivot.iloc[query_index, :].values.reshape(1, -1), n_neighbors=6)

for i in range(0, len(distances.flatten())):
    if i==0:
        print('Recommendations for', format(us_canada_user_rating_pivot.index[query_index]), ':')
    else:
        print('{0}: {1}, with distance of {2}:'.format(i, us_canada_user_rating_pivot.index[indices.flatten()[i]],distances.flatten()[i]))
#testing of the made model and identifying the corresponding cosine distance along with recommendations        


# # Collaborative Fitering Using Matrix Factorization:

# In[183]:


#if any of the values in userID,bookTitle and bookRating are Nan then fill them with 0
us_canada_user_rating_pivot2 = us_canada_user_rating.pivot_table(index = 'userID', columns= 'bookTitle', values = 'bookRating').fillna(0)


# In[184]:


#gives information of top 5 rows of the pivot table
us_canada_user_rating_pivot2.head()


# In[185]:


us_canada_user_rating_pivot2.shape #gives the size of the us_canada_user_rating_pivot2


# In[186]:


x = us_canada_user_rating_pivot2.values.T  #for making transpose of the dataframe
x.shape  #it gives information of size of the matrix x


# In[187]:


#n_components represents the no of columns we need and random_state is the random value generator 
SVD = TruncatedSVD(n_components=12, random_state=17)  #used for dimentionality reduction
matrix = SVD.fit_transform(x)
matrix.shape


# In[188]:


#calculation correlation with data obtained 
corr = np.corrcoef(matrix)
corr.shape


# In[190]:


#storing column names into us_canada_book_title
us_canada_book_title = us_canada_user_rating_pivot2.columns
#converting titles into list and storing in us_canada_book_list
us_canada_book_list = list(us_canada_book_title)
#identifying corressponding to the book
recommended_book = us_canada_book_list.index("Harry Potter and the Sorcerer's Stone (Book 1)")
#storing value into recommended_book
print(recommended_book)


# In[191]:


corr_recommended_book = corr[recommended_book]
#list of recommendation depending on correlation btw 0.9 to 1.0 which is strongly recommended books
recommendations = list(us_canada_book_title[(corr_recommended_book<1.0) & (corr_recommended_book>=0.9)])
print(*recommendations, sep="\n")


# In[ ]:





# In[ ]:




